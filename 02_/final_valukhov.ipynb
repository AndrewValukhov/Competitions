{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация обращений граждан"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnE1_J-4dhSR"
   },
   "source": [
    "## Загрузка библиотек и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from simpletransformers.language_representation import RepresentationModel\n",
    "from scipy.special import softmax\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_dataset_test.csv\")\n",
    "df = pd.read_csv(\"train_dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию для очистки одного обращения. В обращении будем оставлять только русские буквы, приводить будем к нижнему регистру, удлять всю пунктуацию.\n",
    "\n",
    "Также будем отбрасывать некоторые однобуквенные и двухбуквенные \"мусорные\" остатки фраз. Ряд сокращений заменим на полные слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \n",
    "    text = \" \".join((re.sub(r'[^а-яА-ЯёЁ]', ' ', text).split())).lower()\n",
    "    \n",
    "    stop_phrases = []\n",
    "    garbage_replacement = [\" \" for phrase in stop_phrases]\n",
    "    \n",
    "    for from_, to in zip(stop_phrases, garbage_replacement):\n",
    "        text = re.sub(from_, to, text, flags=re.IGNORECASE)\n",
    "        \n",
    "    stop_words = ['д', 'б', 'г', 'x', 'вк', 'го']\n",
    "    \n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    text = \" \".join(['улица' if word == 'ул' else word for word in text.split() if word not in stop_words])\n",
    "    text = \" \".join(['управляющая компания' if word == 'ук' else word for word in text.split() if word not in stop_words])\n",
    "    text = \" \".join(['торговый центр' if word == 'тц' else word for word in text.split() if word not in stop_words])\n",
    "    text = \" \".join(['многоквартирный дом' if word in ['мкд'] else word for word in text.split() if word not in stop_words])\n",
    "    text = \" \".join(['садоводческое некоммерческое товарищество' if word in ['снт'] else word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример очистки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Здравствуйте. На улице Мира &nbsp;было заменено наружное освещение, а именно заменены лампы на &nbsp;энергосберегающие лампы. На протяжении нескольких месяцев освещение улицы отсутствует. Последний раз когда улица была освещена это зима приблизительно до 23:00 да и то не каждый день. А ведь люди работают в 12 часовую смену и многие возвращаются очень поздно. Данная проблема на всех улицах поселка.&nbsp;</p>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Текст Сообщения'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'здравствуйте на улице мира было заменено наружное освещение а именно заменены лампы на энергосберегающие лампы на протяжении нескольких месяцев освещение улицы отсутствует последний раз когда улица была освещена это зима приблизительно до да и то не каждый день а ведь люди работают в часовую смену и многие возвращаются очень поздно данная проблема на всех улицах поселка'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_text(test['Текст Сообщения'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим текст сообщений, тематики и ответственного лица в обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Текст Сообщения</th>\n",
       "      <th>Тематика</th>\n",
       "      <th>Ответственное лицо</th>\n",
       "      <th>Категория</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2246</td>\n",
       "      <td>Помогите начальник Льговского рэс не реагирует...</td>\n",
       "      <td>нарушения связанные с содержанием электросети ...</td>\n",
       "      <td>администрация льговского района</td>\n",
       "      <td>3</td>\n",
       "      <td>помогите начальник льговского рэс не реагирует...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>380</td>\n",
       "      <td>&lt;p&gt;По фасаду дома по адресу ул. Урицкого 22 пр...</td>\n",
       "      <td>аварийные деревья</td>\n",
       "      <td>администрация города курска</td>\n",
       "      <td>3</td>\n",
       "      <td>по фасаду дома по адресу улица урицкого проход...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2240</td>\n",
       "      <td>Агресивные собаки. На радуге там стая из подро...</td>\n",
       "      <td>безнадзорные животные</td>\n",
       "      <td>администрация города курска</td>\n",
       "      <td>1</td>\n",
       "      <td>агресивные собаки на радуге там стая из подрос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>596</td>\n",
       "      <td>&lt;p&gt;На пересечении &amp;nbsp;улиц Сосновская и Бере...</td>\n",
       "      <td>нескошенная сорная растительность в местах общ...</td>\n",
       "      <td>комитет дорожного хозяйства города курска</td>\n",
       "      <td>3</td>\n",
       "      <td>на пересечении улиц сосновская и береговая зав...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                    Текст Сообщения  \\\n",
       "0  2246  Помогите начальник Льговского рэс не реагирует...   \n",
       "1   380  <p>По фасаду дома по адресу ул. Урицкого 22 пр...   \n",
       "2  2240  Агресивные собаки. На радуге там стая из подро...   \n",
       "3   596  <p>На пересечении &nbsp;улиц Сосновская и Бере...   \n",
       "\n",
       "                                            Тематика  \\\n",
       "0  нарушения связанные с содержанием электросети ...   \n",
       "1                                  аварийные деревья   \n",
       "2                              безнадзорные животные   \n",
       "3  нескошенная сорная растительность в местах общ...   \n",
       "\n",
       "                          Ответственное лицо  Категория  \\\n",
       "0            администрация льговского района          3   \n",
       "1                администрация города курска          3   \n",
       "2                администрация города курска          1   \n",
       "3  комитет дорожного хозяйства города курска          3   \n",
       "\n",
       "                                                text  \n",
       "0  помогите начальник льговского рэс не реагирует...  \n",
       "1  по фасаду дома по адресу улица урицкого проход...  \n",
       "2  агресивные собаки на радуге там стая из подрос...  \n",
       "3  на пересечении улиц сосновская и береговая зав...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['Текст Сообщения'].apply(clear_text)\n",
    "df['Тематика'] = df['Тематика'].apply(clear_text)\n",
    "df['Ответственное лицо'] = df['Ответственное лицо'].apply(clear_text)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из тестовой выборки оставим только \"Текст Сообщения\", потому что для предсказания нам запрещено использовать какие-либо колонки кроме текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Текст Сообщения</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Здравствуйте. На улице Мира &amp;nbsp;было заме...</td>\n",
       "      <td>здравствуйте на улице мира было заменено наруж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;Уже вторую неделю не горит уличное освещени...</td>\n",
       "      <td>уже вторую неделю не горит уличное освещение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Не работает освещение во дворе дома 11а по Эне...</td>\n",
       "      <td>не работает освещение во дворе дома а по энерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>После покоса сорной растительности на газоне м...</td>\n",
       "      <td>после покоса сорной растительности на газоне м...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Текст Сообщения  \\\n",
       "0  <p>Здравствуйте. На улице Мира &nbsp;было заме...   \n",
       "1  <p>Уже вторую неделю не горит уличное освещени...   \n",
       "2  Не работает освещение во дворе дома 11а по Эне...   \n",
       "3  После покоса сорной растительности на газоне м...   \n",
       "\n",
       "                                                text  \n",
       "0  здравствуйте на улице мира было заменено наруж...  \n",
       "1       уже вторую неделю не горит уличное освещение  \n",
       "2  не работает освещение во дворе дома а по энерг...  \n",
       "3  после покоса сорной растительности на газоне м...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['Текст Сообщения']]\n",
    "test['text'] = test['Текст Сообщения'].apply(clear_text)\n",
    "test.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заполнение редких категорий по ключевым словам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на количество обращений в каждой категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     954\n",
       "0     478\n",
       "16    149\n",
       "8     139\n",
       "4     108\n",
       "10     48\n",
       "7      27\n",
       "1      25\n",
       "11     19\n",
       "5      12\n",
       "13     11\n",
       "6      10\n",
       "15      7\n",
       "9       5\n",
       "14      4\n",
       "2       3\n",
       "12      1\n",
       "Name: Категория, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Категория'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что всего 17 категорий, причем существенная часть из них - очень редкие. На редких примерах сложно будет обучать модели, и они будут лишь приносить шум. Поэтому попробуем подобрать для редких категорий ключевые слова, и найти в тестовой выборке такие обращения, которые содержат подобранные нами ключевые слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим категорию 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Текст Сообщения</th>\n",
       "      <th>Тематика</th>\n",
       "      <th>Ответственное лицо</th>\n",
       "      <th>Категория</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1576</td>\n",
       "      <td>&lt;p&gt;Не могу получить сертификат&lt;/p&gt;</td>\n",
       "      <td>тестовая категория</td>\n",
       "      <td>ответственный пми</td>\n",
       "      <td>12</td>\n",
       "      <td>не могу получить сертификат</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     Текст Сообщения            Тематика  \\\n",
       "652  1576  <p>Не могу получить сертификат</p>  тестовая категория   \n",
       "\n",
       "    Ответственное лицо  Категория                         text  \n",
       "652  ответственный пми         12  не могу получить сертификат  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Категория'] == 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С учетом того, что фраза всего одна, и ее тематика - \"тестовая категория\", то можно предположить, что проходило какое-либо тестирование платформы. И такой случай редкий, поэтому просто отбросим эту категорию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим категорию 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['здравствуйт не могу поставить ребёнка на очередь в детский сад через госуслуги указано что данная услуга недоступна в нашем регионе хотя за две недели до моей последней попытки июня подать можно было когда будет урегулирован это вопрос и люди смогут записать ребёнка на очередь',\n",
       " 'добрый день администратор сообщества блокирует участников без объяснения причины',\n",
       " 'доброе утро помогите разобраться в проблеме в личном кабитете госуслуг хочу подать заявку на онлайн голосование к сожалению появляется ошибка данные вашей учётной записи не сопоставлены с данными содержащимися в регистре избирателей участников референдума цик россии данные в личном кабинете госуслуг сверил все верно']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Категория'] == 2]['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь всего 3 образца обращений, одно из которых объединяет и проблему с госуслугами, и очередь в детский сад, второе - очень размытое, третье - сокрее всего слишком частное.\n",
    "\n",
    "Поэтому из-за редкости категории, также лучшее ее просто отбросить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее рассмотрим категорию 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['муп льговское не платят зарплату уже больше двух месяцев муж работает за спасибо которое спасибо тоже не получает руководитель горит зарплату получите не раньше апреля сколько можно терпеть безответственность данной организации по просьбе знакомой пишу',\n",
       " 'добрый день июля года я был направлен на прохождения обучения и получения дополнительного образования по направлению органов службы занятости населения в гаоу дпо курской области курский областной центр подготовки и переподготовки кадров жкх на оператора котельной от даты постановки на учёт по безработице и до июля я активно искал работу у меня трое детей и прожить на одно пособие просто не возможно июля года я официально трудоустроился в соответствии с законом рф при направлении безработного гражданина на профессиональное обучение он считается занятым в случае если в этом периоде безработный гражданин самостоятельно трудоустроился но продолжает профессиональное обучение регулярно посещает занятия выполняет объем учебной программы этот гражданин имеет право на оплату обучения и выплату стипендии за счет средств службы занятости августа года мной в цзн октябрьского района курской области был предоставлен приказ с места работы на что руководитель ответил мне что я не имел права трудоустраиваться и теперь должен вернуть деньги за обучение и медкомиссию а также прекращается моё обучение и выплата стипендии согласно приказу минтруда россии от н об утверждении правил в соответствии с которыми органы службы занятости осуществляют социальные выплаты гражданам основаниями для принятия сотрудниками центра занятости населения решения о прекращении выплаты стипендии является истечение периода обучения гражданина самовольное прекращение обучения смерть обучаемого и т трудоустройство гражданина во время прохождения обучения по направлению органов службы занятости населения не является основанием для отчисления обучаемого и возврата стипендии августа в моем личном кабинете на сайте комитета по труду и занятости курской области я обнаружил приказ от о снятии с учёта т е получается я учился и состоял на учёте в качестве безработного одновременно и назначена выплата пособия по безработице в размере рублей за период с по года приказа о назначении стипендии и направление на обучение я так и не увидел на основание вышеизложенного я считаю что действия центра занятости это прямое нарушение моих прав и действующего закона в связи с этим прошу провести проверку по изложенным фактам применить в отношении сотрудников допустивших нарушение закона меры дисциплинарного взыскания уведомить о принятом решении на электронный адрес',\n",
       " 'добрый день подала документы на участие в конкурсе по включению в резерв на руководящую должность на госслужбе мне позвонили и пригласили на тестирование по телефону сказали прибыть к по адресу интернациональная для прохождения теста более подробной информации не было адрес указали неверный как выяснилось прибыв в академию госслужбы мне предложили пройти на компьютере тест состоящий из вопросов на время с тестом я заранее не была ознакомлена даже с тематикой в итоге получила из баллов отвечая на вопросы с которыми я не сталкивалась никак в жизни в итоге я не прошла второй этап считаю что проведение таких тестов это цель провести отбор для галочки чтобы вакантные места заняли нужные люди коррупцию таким образом не победить если бы я знала тему теста и подготовилась то я набрала бы нужное количество баллов мое образование опыт работы и личная высокая ответственность могла бы пригодиться нашему краю прошу не оставить без внимание это письмо',\n",
       " 'добрый день с апреля месяца не получала выплаты какая причина']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Категория'] == 14]['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь 2 человека жалуются на обучение от центра занятости, и еще 2 челоека - на задержки зарплаты в гос.учреждении (что может быть очень широкой категорией)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим обучение от центра занятости как ключевые слова и найдем что-то подходящее в тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[611]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_14 = list(test[test['text'].str.contains(r'^(?=.*обучен)(?=.*занято)')].index)\n",
    "cat_14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нашлась 1 фраза, сохраним ее индекс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в одном из обращений было упоминание коррупции, попробуем выделить ключевое слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_14.extend(test[test['text'].str.contains(r'^(?=.*коррупц)')].index.to_list())\n",
    "len(cat_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавилось еще 2 фразы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь, где ключами будут индексы обращений в тестовой выборке, а значениями - категории. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_cats = {}\n",
    "for idx in cat_14:\n",
    "    hand_cats[idx] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее рассмотрим категорию 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['здравствуйте все мы пишем и говорим только об одном дороги больницы плохая власть и так далее слежу уже пару лет за сообществами курска но не разу не видел чтобы кто то писал и жаловался на операторов сотовой связи по городам курской области вопрос в обслуживании сотовой связи практически нет но можно было бы улучшить качество обслуживания все же на дворе век проблема появляется на выездах из города а именно на трассах области многие друзья сталкиваются с такой проблемой дозвониться возможно только на номер и все почему так происходит говорить о каких то конкретных участках дорог не будем везде есть такая проблема возьмем например дороги такие как курск железногорск курск обоянь курск щигры курск льгов рыльск курск суджа выезжая из курска в любом направлении мы сталкиваемся с проблемой связи любого оператора нет сети проверено на личном опыте когда едем например в направлении москва санкт петербург сеть в есть везде и всегда курская область пока делает дороги ремонтирует больницы и т в то время как кто то сейчас стоит на дороге с пробитым колесом и не может дозвониться или еще хуже кому то стало плохо за рулем и также не может дозвониться своим родным и близким так вот дайте свое мнение в комментарии очень хотелось бы получить комментарий от руководителей администрации курской области которые курируют данный вопрос спасибо за внимание думаю что многие поддержат',\n",
       " 'с по адресу гагарина нет доступа в сеть интернет компания мтс не предпринимает мер для устранения неполадки по данное время',\n",
       " 'здравствуйте по телефону не слышу товар поступил февраля по адресу пр кт вячеслава клыкова и пришла на почту февраля и спросила почему наш товар не привезли до двери сказали ожидайте и жду курьера целую неделю что за курьер не несут ответственности и ленивые работники на почте не могу оставить с тремя детьми и каждый раз бежать на почту',\n",
       " 'нет вещания радио россии курск приходится слушать радио россии брянск хотелось бы как ранее лет назад прогноз погоды новости радиоцилнный фон каждое утро и все оповещения',\n",
       " 'очень плохой мобильный интернет отсутствие проводного интернета не позволяют ребенку полноценно обучаться по школьной программе в дни болезни и дни карантина']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Категория'] == 9]['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут заметно, что люди жалуются на проблемы со связью - в частности с интернетом (мобильным)\n",
    "\n",
    "Попробуем найти фразы с такими ключевыми словами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[707]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_9 = test[test['text'].str.contains(r'^(?=.*интерне)(?=.*сотов)')].index.to_list()\n",
    "cat_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in cat_9:\n",
    "    hand_cats[idx] = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нашли одну, добавили ее индекс в словарь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотри категорию 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['добрый день прошу обратить внимание на неудовлетворительное состояние спортивной площадки школы курска планируется ли реконструкция стадиона в рамках реализации национальных проектов если да то в какие сроки',\n",
       " 'отсутствие полной поддержки любительскому хоккею мы сейчас находимся в сочи представляем курская область в ночной хоккейной лиги и никакой поддержки со стороны области нету игроки приехали в чем было стыдно просто смотреть как игры команды со всей россии одеты и как их представляют а мы простите как бомжи',\n",
       " 'здравствуйте у нас в курск есть замечательный парк железнодорожников но кроме памятников там ничего нет хотелось что бы в данном парке появились спортивные тренажёры и детская площадка с одной стороны парка спортивные тренажёры в с другой стороны парка детская площадка',\n",
       " 'здравствуйте во льгове процветает коррупция по всем направлениям вот например на протяжении около лет в фоке физкультурно оздоровительном комплексе процветает коррупционная схема в бюджетных деньгах в фоке открыто очень много секций по разным направлениям например как тренера которые получают деньги из бюджета города льгова собирают дань со своих учеников определенную таксу потом с директором фока пилят эти средства какие то договора чеки и подтверждающие документы не дают думаем теперь понятно и вам почему именно так а также в фоке оформлено очень много мертвых душ опять же средства за мертвые души получает директор фока михаил вячеславович тивелев и куратор вячеслав петрович куцев всех финансовых вопросах под покровительством м в тивелева просим провести проверку по всем направлениям возможно местная прокуратура также покрывает в данном вопросе этих лиц разберитесь пожалуйста',\n",
       " 'добрый день вопрос от жителй курска проживающих по адресам ыйкирпичный переулок и ий кирпичный переулок уже много раз обращались в администрацию по поводу установки детской площадки по данным адресам площадка которая имеется в данный момент не соответствует нормам она советского образца конструкции старые ржавые травмоопасные куда нам можно обратиться с просьбой установить бесплатно детскую спортивную и игровую площадку бесплатно по данным адресам в какое ведомство нужно обратиться',\n",
       " 'проблема заключается в отсутствии детской площадки возле домов по улице сумская а конорева и т прошу поставить детскую площадку',\n",
       " 'здравствуйте в щигровском районе в зелёной роще находится детский лагерь им в терещенко на данный момент это место трудно назвать детским лагерем его просто разрушили домики столовая склады медицинский пункт все разбито объясните почему данный лагерь единственный в районе перестал работать и почему он находится в таком удручающем состоянии']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Категория'] == 15]['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь видно, что люди жалуются на детские площадки, плокие конструкции на них и плохое обустройство парков.\n",
    "\n",
    "Попробуем выделить ключевые слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_15 = test[test['text'].str.contains(r'^(?=.*детск)(?=.*площ)(?=.*установ)|(?=.*детск)(?=.*площ)(?=.*качел)|(?=.*детск)(?=.*площ)(?=.*парк)')].index.to_list()\n",
    "len(cat_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in cat_15:\n",
    "    hand_cats[idx] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего нашли 16 таких обращений и добавили их индексы в словарь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее рассмотрим категорию 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['прошу включить меня и мою семью в очередь на получение материальной помощи',\n",
       " 'прошу включить меня в очередь на получение материальной помощи как малоимущей семье или в очередь на участие в социальном контракте',\n",
       " 'посёлок находится в красной зоне в школе очень много заболевших дети чьи родственники больны коронавирусом продолжают посещать занятия больных с поражением лёгких отказываются госпитализировать и больных с каждым днём всё больше',\n",
       " 'добрый вечер как можно записаться на соц контракт',\n",
       " 'обращение собственников торговых помещений торгового центра олимпийский в связи с изданием постановлением губернатора курской области от года пг о режиме нерабочих дней в курской области в период с октября года по ноября года',\n",
       " 'добрый день роман владимирович хочу обратиться к вам с таким вопросом почему вы и ваши коллеги считаете продление нерабочих дней целесообразным то что дети не ходят в сад и школу не работают торговые центры так родители этих детей ходят в продуктовые магазины пользуются общественным транспортом ходят по гостям и приносят вирус домой в нашей области и так очень низкий уровень жизни а вы хотите чтобы стал ещё ниже куда ещё из за того что торговый центр сейчас закрыты в интернет магазинах подняли цены на одежду и обувь а сейчас простите самый сезон не говоря уже о нас взрослых нужно одеть и обуть своих детей а по этим ценам которые сейчас присутствуют на сайтах это практически невозможно дистанционное образование для школьников это просто квест дети элементарно не могут воспринять информацию дома сами а многие родители далеко не преподаватели по своей сути чего вы добиваетесь продлением выходных я считаю что можно ограничится более мягкими ограничениями такими как закрытие фудкортов общепита фитнес залов развлечений любых массовых мероприятий а то что вы и ваши коллеги делаете считаю простым издевательством над простыми людьми надеюсь на понимание',\n",
       " 'добрый день родственница проживает в районе переболела анализ на к небрали сказали берут только после кт и сейчас у неё болит грудь и т необходимо делать кт так как флюра показала что повреждение лёгких ест в местной полеклиннике отправляют в железногорск сказали запишут дня через два позвонят скажут куда с золотухино нет прямых не электричек не автобусов и расстояние в раза дальше чем от курска ей дышать и так тяжело да ещё такая дорога вопрос можно это сделать в курске в комитете здравоохранение сказали что глав врач принемают решения куда направлять дозвонится до светланы николаевны невозможно трубку не берут вообще буду ещё утром пробывать хотели сней поговорить вообще непонятно почему она принемают такие решения отправлять больных людей на такие расстояния болезнь как известно быстро прогрессирует нужно лечение естественно без результатов его не назначат мы просто ждём пока болезнь её убевает помогите пожалуйста',\n",
       " 'прошу оказать содействие в получении путевки в загородний лагерь олимпиец на смену моей дочери амелиной ангелине александровне уч це а класса школы в связи с тем что мы являемся многодетной семьей',\n",
       " 'роман владимирович вот почему вы не боритесь с короной как следует почему вы всех вакцинируете но при этом о наших студента никто даже не думает вы вводите какие то беспонтовые короновирусные ограничения которые не помогают и не снижают риски заболеваемости надо ввести новое ограничения и посадить студентов на дистанционное обучения при этом отменить льготы на проезд что бы они не ездили а сидели и учились дома почему я должна рисковать своим ребёнком неизвестно с кем контактировали его одногрупник и а он с ними общается сейчас не дай бог он заболее и что и неизвестно выличится ли он или нет при этом он не привит потомучто ему лет я не прошу дистанционку ради того что бы он дома сидел я прошу вас что бы вы ввели дистанционное обучения ради жизни зтудентов что бы они были обезопасены я считаю что дистанционное обучения должно начаться с конца сентября и до февраля включительно сейчас зима рост заболеваемости увеличится надеюсь что бы действительно люди и не будите рисковать жизнями наших детей незряже мы вас вибиоаем надо сделать хоть что то и для наших детей',\n",
       " 'сообщаю что в ночь с на а конкретно до ч утра доносилась громкая музыка с новой боевки т к в курске действует закон об административных правонарушений зко об административных правонарушений нарушено спокойствие граждан в ночное время с до прошу провести проверку и исключить в дальнейшем подобные случаи']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Категория'] == 6]['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что люди здесь обращались за материальной помощью, аппелировали к тому, что имеют многодетные и малообеспеченные семьи.\n",
    "\n",
    "Попробуем подобрать такие ключевые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_6 = test[test['text'].str.contains(r'^(?=.*матер)(?=.*помощ)|(?=.*малообеспечен)(?=.*семь)|(?=.*многодетн)(?=.*сем)')].index.to_list()\n",
    "len(cat_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in cat_6:\n",
    "    hand_cats[idx] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего 10 таких фраз, добавили их в словарь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим категорию 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['предлагаю провести проверку качества данного хлеба и соблюдения технологии производства в целом на заводе в хлебе обнаружена мышиная какашка',\n",
       " 'на перекрестке улица сумской и дейнеки у сквера с памятником дейнеки на тротуаре и газоне более недель с припаркованных машин и со столов торгуют фруктами и овощами заняли половину тротуара и затоптали газон напротив после торговли оставляют мусор и свои подсобные предметы торговли примите меры',\n",
       " 'прошу помощи в защите прав жителей домов и улицы гагарина города курска дело в том что в бывшем торговом комплексе курские зори расположенном между указанными домами открылся магазина магнит и построена металлическая разгрузочная площадка во дворе этих домов работы по разгрузке товаров после открытия магазина магнит мешают жителям у которых окна выходят во двор обустройство разгрузочной площадки во дворе наших домов нарушает законодательство российский федерации основным документом который регламентирует деятельность торговых точек в жилой зоне являются санитарные нормы и правила сп предприятия торговли санитарно эпидемиологические требования к организациям торговли и обороту в них продовольственного сырья и пищевых продуктов санитарно эпидемиологические правила пункт указанных норм гласит что деятельность объектов торговли не может нарушать или ухудшать условия проживания или отдыха жильцов дома пункт определяет порядок загрузки продуктов в магазин загрузка должна осуществляться исключительно с торца жилого здания не имеющего окон пункт санпин уточняет что загружать продукцию или иные материалы в помещения общественного назначения со стороны дома где есть входы в квартиры и окна жилых помещений не допускается соблюдать нормы санпин обязаны все об этом прямо говорит пункт ст федерального закона от фз о санитарно эпидемиологическом благополучии населения где говорится что соблюдение утвержденных в установленном порядке санитарных правил является обязательным как для граждан так и для организаций',\n",
       " 'торговля и попрошайничество в надземном переходе между торговый центр гринн и торговый центр олимпийский особенно в выходные дни уже второй год администрация цо ни чего не делает что бы устранить это безобразия от администрации цо',\n",
       " 'прошу обратить внимание администрацию магазина линия на грязные тележки учитывая нынешнюю проблему эпидобстановки к тележкам в магазине линия страшно прикасаться прошу навести порядок',\n",
       " 'добрый день долгое время закрывала глаза на работу единственного магазина в нашей деревни но после недавних событий сил молчать больше нет в магазине огромное количество товара не надлежащего качества с истекшим сроком годности один из которых был куплен а именно шоколад фирмы альпен гольд со сроком реализации до употребление этого товара стало причиной пищевого отравления моих детей чек предоставить нет возможности т к их не выдают вообще что является ещё одним грубым нарушением и конечно же хамское отношение продавца францевой нелли на мою притензий ссылаясь на вышеизложенное прошу вас произвести проверку и принять соответствующие меры в отношении руководства данного магазина и продавцов допустившим продажу испорченного товара заранее спасибо',\n",
       " 'льгов хочу услышать мнение каждого кто осмелиться написать комментарий а также прошу обратить внимание роспотребнадзор роспотребнадзор надо торговцев с рыбой в центре разогнать рыба в кровавой воде у продавцов нет санитарных книжек куда смотрит роспотребнадзор есть ли документы на рыбу а так же можно ли продуктами торговать на улице в грязи какие требования к продаже живой рыбы разве можно торговать дохлой рыбой да и рыба перевозится в не оборудованных автомобилях продавцы грязные и постоянно меняются оформленны ли они в налоговой как работники или это просто случайные люди без документов разрешающий торговлю есть ли у них санитарные книжки нарушение санитарно гигиенических требований могут поставить под угрозу здоровье покупателей грязь антисанитария и это центр города грязная кровавая вода выливается тут же вонь и ужас какая то дикость',\n",
       " 'здравствуйте от моего лица было обращение с жалобой на оказание услуги ответ по данному обращению меня не удовлетворил так как я не прошу госжилинспекцию предоставить мне видио с камер видеонаблюдения день время указано было в обращении а я прошу проверить качество услуги и указать истинную причину по которой не работали камеры видеонаблюдения т к услуга оплачена но не предоставлена мне хочется знать причину нерабочих камер на тот момент и чтобы виновные оплатили все соответсвующие штрафы за некачественное оказание услуг считаю что нарушены мои права потребителя данной услуги все скрины переписки прилагаю ниже',\n",
       " 'торговля кобасными и мясными изделиями без использования холодильного оборудования на т н продуктовом рынке при температуре наружного воздуха осуществляется массовая торговля колбасными мясными и другими скоропортящимися продуктами без использования холодильного оборудования',\n",
       " 'ежедневно происходит незаконная продажа продуктов питания от до продавцов стоят вдоль тротуара затрудняя движения людей с детскими колясками продавцы стихийного рынка грубят в ответ на замечания и произносят нецензурные выражения в присутствии несовершеннолетних весь мусор и остатки продуктов сбрасываются в кустарник на газоне привлекая бездомных животных и грызунов также в этом кустарнике справляют естественную нужду прошу принять меры и остановить незаконную торговлю а также ликвидировать незаконную свалку в кустарнике',\n",
       " 'прошу вас пожалуйста установить банкомат втб и сбербанка в вокзале михайловский рудник хотелось также что бы вы сделали наш вокзал цифровым т е о прибытии и об отправлении говорил не человек а специальная программа']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Категория'] == 13]['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь уже становится заметно, что категорию все труднее обработать несоклькими ключевыми словами - присутствуют темы и про некачественные продукты, и про эпидобстановку, и про банкомат.\n",
    "\n",
    "Поэтому лучшее ее пропустить и применять для классификации модели машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим категорию 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['прошу вас привести в порядок тротуар в доль школьного забора на улица и франко тротуар находится в не удовлетворительно состоянии данный тротуар ремонтировался ещё при ссср после распада ссср тротуар не ремонтировался неужели так сложно положить новый асфальт и установить хотя бы скамейку с урной что бы пенсионеры отдыхали',\n",
       " 'прошу вас провести онлайн игру послещенную новому году и рождеству было бы замечательно что бы студенты учебных заведений в данной игре учавствовали а в качестве подарков можно было бы сделать складкие подарки с логотипом партии единая россия и сертификат',\n",
       " 'прошу вас направить письмо руководству сах завода что бы они замени флаг рф',\n",
       " 'дом книги объект культурного наследия буква о скоро упадёт на голову людям проведите срочные противоаварийные работы барельефа',\n",
       " 'памятник свиридову имеет повреждения постамента отваливается облицовочная плитка почему такое ужасное качество работ это не допустимо тем более в центре города',\n",
       " 'уважаемый роман владимирович к вам обращаются жители с сараевка зуевского сельского совета солнцевского района курской области очень просим вас дать поручение вашим подчиненным а именно главе солнцевского района и председателю зуевского сельского совета о том чтобы в нашем селе сделали ограждение вокруг кладбища где покоятся наши земляки такого позора такой изгороди как около кладбища в нашем селе нигде нет фото прилагается также просим убрать мусор скопившийся на кладбище и попилить сухие деревья и ветки очень хотелось бы чтобы ограждение было как в других селах нашего района и чтобы к нам хоть иногда появлялся председатель сельского совета который с момента его назначения ни разу не был и не интересовался проблемами села спасибо за понимание благодарные жители села сараевка',\n",
       " 'прошу вас обустроить север если его можно назвать сквером возле жд вокзала там где стоит статуя пеликан хотелось что бы вместо пеликана вы установили фантан и по кругу установили лавочки с освещением и соответственно уложили это место тротуарной плиточкой хотелось что бы фантан напоминал жителям и гостям символику курской области например как на фотографии или можно просто сделать фантан с подсветкой так сказать поющий фантан пеликана можно и не убирать его можно установить где нибудь в другом месте т е в данном сквере но не в центре',\n",
       " 'прошу вас повесить баннер с мая между столами на мосту через р сейм также прошу что бы придать людям праздничное настроение повесить настолбы символики государства и флаг победы',\n",
       " 'отбитые буквы на памятнике прикручены саморезами которые уже проржавели ранее буквы были изготовлены из металла а теперь пластик',\n",
       " 'прошу вас украсить автомобильный мост через р сейм поверьте пожалуйста поздравления с новым городом и рождеством также прошу вас повесить такой баннер на опоры рядом с остановкой поворот',\n",
       " 'когда в селе большое жирово будут выборы главы сельсовета куда и когда приходить людям почему нет брошюр кандидатов',\n",
       " 'хочу выразить благодарность администрации льгова за такую красавицу вы все правильно сделали и очень красиво наряд ли новогоднию ель дети в восторге ещё раз огромное спасибо спасибо что создали новогоднее настроение']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Категория'] == 5]['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь сразу видно, что люди жалуются на состояние памятников, хвалят новый год и призывают повесить баннеры.\n",
    "\n",
    "Темы узкие, поэтому попробуем подобрать ключевые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_5 = test[test['text'].str.contains(r'^(?=.*памятник)|новогодн|музык|постаме|баннер')].index.to_list()\n",
    "len(cat_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in cat_5:\n",
    "    hand_cats[idx] = 5\n",
    "len(hand_cats.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы сделали словарь из 41 фразы, для которых вручную проставим категорию в зависимости от ключевых слов. Но это будет сделано после того, как мы спрогнозируем для тестовой выборки принадлежность к категории при помощи моделей машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также отросим все редкие категории для которых будем проставлять категорию из словаря, они не будут присутствовать в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['Категория'].isin([12, 2, 14, 9, 15, 6, 5]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIFh_dnOhj1V"
   },
   "source": [
    "## Выделим выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем обучающую и валидационную выборку, размером 10% от обучающей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Категория']\n",
    "X_train, X_val, y_train, y_val = train_test_split(df, y, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку у нас все еще очень мало примеров для определенных категорий, будем делать процедуру апсэмплинга редких категорий - будем доводить количество примеров до более высокого количества, беря пример несколько раз в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(df, ts, smooth, random_state=2):\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    top = data['Категория'].value_counts(normalize=True)[data['Категория'].value_counts(normalize=True) > ts].index\n",
    "    \n",
    "    multipliers = []\n",
    "    ceil = data['Категория'].value_counts().iloc[0]\n",
    "    for idx, n in zip(data['Категория'].value_counts().index, data['Категория'].value_counts()):\n",
    "        if idx not in top:\n",
    "            multiplier = round(ceil / (smooth * n))\n",
    "            \n",
    "        else:\n",
    "            multiplier = 1\n",
    "\n",
    "        multipliers.append(multiplier)\n",
    "\n",
    "        upsampled = pd.DataFrame()\n",
    "\n",
    "        for target_type, multiplier in zip(data['Категория'].value_counts().index, multipliers):\n",
    "            upsampled = pd.concat([upsampled] + [data.loc[data['Категория'] == target_type, :]] * multiplier)\n",
    "            \n",
    "    upsampled = shuffle(upsampled, random_state=random_state).reset_index(drop=True)\n",
    "            \n",
    "    return upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, увеличим количество обращений из редких категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     859\n",
       "0     430\n",
       "10    172\n",
       "11    170\n",
       "13    170\n",
       "7     168\n",
       "1     161\n",
       "16    134\n",
       "8     125\n",
       "4      97\n",
       "Name: Категория, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsed = upsample(X_train, 0.03, 5)\n",
    "y_train = upsed['Категория']\n",
    "upsed['Категория'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученную обучающую выборку будем использовать для векторизации обращений.\n",
    "\n",
    "Возьмем открытый предобученный русскоязычный энкодер типа Bert - \"cointegrated/rubert-tiny2\" с huggingface\n",
    "https://huggingface.co/cointegrated/rubert-tiny2\n",
    "\n",
    "Преимуществом этой модели являются ее маленький размер и очень высокая скорость работы.\n",
    "\n",
    "И при помощи него будем получать векторы эмбеддинги для каждого обращения.\n",
    "\n",
    "Загрузим модель и токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# # \"sberbank-ai/sbert_large_mt_nlu_ru\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для векторизации. В ней оставим возможность для векторизации по двум типам - взять CLS-вектор из начала каждой реплики или усредненнный вектор со всех слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(data, cls=True, length=128, test=False):\n",
    "    \n",
    "    if test == 'test':\n",
    "        col = 1\n",
    "    elif test == 'cv':\n",
    "        col = 0\n",
    "    else:\n",
    "        col = 5\n",
    "    \n",
    "    emb = np.zeros([1, 312])\n",
    "    batch_size = 128\n",
    "\n",
    "    for index in range(0, len(data), batch_size):\n",
    "\n",
    "        batch = list(data.iloc[index: min(index + batch_size, data.shape[0]), col])\n",
    "        \n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt', max_length=length)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**{k: v.to(model.device) for k, v in encoded_input.items()})\n",
    "        if cls:\n",
    "            embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "        else:\n",
    "            embeddings = model_output.pooler_output\n",
    "            \n",
    "        embeddings = torch.nn.functional.normalize(embeddings)\n",
    "        emb = np.vstack((emb, embeddings))\n",
    "\n",
    "    return emb[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем обучающую и валидационную выборку.\n",
    "\n",
    "Будем брать усредненный вектор со всех слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 12.6 s, total: 1min 17s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.DataFrame(embed(upsed, test=False, cls=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.91 s, sys: 745 ms, total: 5.66 s\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embs_val = pd.DataFrame(embed(X_val, test=False, cls=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60NotS9ehbO5"
   },
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert_embeddings + logisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала обучим простую модель логистической регрессии на векторах-эмбеддингах, которые мы извлекли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "jc-KKFlWf6_N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', max_iter=200, random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(random_state=0, penalty='l2', C=1, class_weight='balanced', \n",
    "                         max_iter=200)\n",
    "logit.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим целевую метрику на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7561862357914988"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout = embs_val\n",
    "\n",
    "holdout_probs = pd.DataFrame(logit.predict_proba(holdout), columns=logit.classes_)\n",
    "h_i = holdout_probs.idxmax(axis=1)\n",
    "        \n",
    "for col in holdout_probs.columns:\n",
    "    holdout_probs[col].values[:] = 0\n",
    "            \n",
    "for row, idx in zip(holdout_probs.iterrows(), h_i):\n",
    "    row[1][idx] = 1\n",
    "    \n",
    "roc_auc_score(y_val, holdout_probs, multi_class='ovo', labels=logit.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение целевой метрики составило около 0.76, при этом мы отбросили редкие категории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine_tuning cointegrated/rubert-tiny2 при помощи библиотеки simple_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее попбробуем дообучить рассмотренный энкодер на нашей обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно подготовить обучающую и валидационную выборку в формате text-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = upsed[['text', 'Категория']]\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.columns = [\"text\", \"labels\"]\n",
    "\n",
    "eval_data = X_val[['text', 'Категория']]\n",
    "eval_df = pd.DataFrame(eval_data)\n",
    "eval_df.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категории должны идти строго по порядку, поэтому перекодируем наши категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_cat = {k: v for k, v in zip(df['Категория'].value_counts().sort_index().index, \n",
    "                                range(len(df['Категория'].value_counts())))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    859\n",
       "0    430\n",
       "6    172\n",
       "7    170\n",
       "8    170\n",
       "4    168\n",
       "1    161\n",
       "9    134\n",
       "5    125\n",
       "3     97\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['labels'] = train_df['labels'].map(cut_cat)\n",
    "eval_df['labels'] = eval_df['labels'].map(cut_cat)\n",
    "train_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще раз - на обучающей выборке мы сделали апсэмплинг, валидационная оставлена без изменений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно задать веса классов - они будут обратно пропорциональны встречаемости класса в выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = list(len(train_df['labels']) / (10 * np.bincount(train_df['labels'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся библиотекой simple_transformers и дообучим rubert-tiny2 как классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# зададим конфигурацию модели - вос\n",
    "model_new = ClassificationModel(\n",
    "    model_type='bert',\n",
    "    model_name=\"cointegrated/rubert-tiny2\", \n",
    "    tokenizer_name=\"cointegrated/rubert-tiny2\", \n",
    "    num_labels=len(train_df['labels'].value_counts()),  # 10 категорий\n",
    "    weight=weight, # посчитанные выше веса\n",
    "    use_cuda=False,\n",
    "    args={\"reprocess_input_data\": True, \n",
    "          \"overwrite_output_dir\": True, \n",
    "          'num_train_epochs': 4, # 4 эпохи\n",
    "          'manual_seed': 42, \n",
    "          'optimizer': 'AdamW',\n",
    "          'evaluate_during_training': False, \n",
    "          'weight_decay': 0,\n",
    "          'scheduler': 'linear_schedule_with_warmup', \n",
    "          'sliding_window': False,\n",
    "          'config': {\"output_hidden_states\": True} # делаем возможность использования дообученной модели как энкодера\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проводим дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bab99b8e3f24fbbbf276ebfb7a665a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f74efa19d34325a01ce3f58b2e2628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2571efed6f84a0eb51aa48d5be1128b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7314d4c066164aea83cdf82cfc74920c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ef61a960b4b8b9d498ef1e21e99f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034ad5f03fc842a7b5478fceb80042e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 21s, sys: 3min 35s, total: 26min 56s\n",
      "Wall time: 7min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1244, 0.8023610526031045)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_new.train_model(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим результаты дообучения на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ff145107ee4241b0cdd4acd871d715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96cbe88da20436aae1b674b85a3d010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0bab4d0a6d4af5b53b119584a8d7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f592fc546c5c4c41a0ce2663fa767cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result, model_outputs, wrong_predictions = model_new.eval_model(eval_df)\n",
    "predictions, raw_outputs, embs, smth_else = model_new.predict(list(eval_df['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем предсказания дообученного bert как классификатора и проверим на целевой метрике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "yfNWUQJnjkMW"
   },
   "outputs": [],
   "source": [
    "def one_label_to_many(df, classes = [x for x in range(17)]):\n",
    "    y_test = []\n",
    "    min_class = min(classes)\n",
    "    count_class = len(classes)\n",
    "\n",
    "    for ll in df:\n",
    "        mass = [0]*count_class\n",
    "        mass[int(ll) - min_class] = 1\n",
    "        y_test.append(mass)\n",
    "\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    95\n",
       "0    48\n",
       "9    15\n",
       "5    14\n",
       "3    11\n",
       "6     5\n",
       "4     3\n",
       "7     2\n",
       "1     2\n",
       "8     1\n",
       "Name: Категория, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8130506189716715"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_probs = one_label_to_many(predictions, classes = [x for x in range(len(cut_cat))])\n",
    "y_val_s = y_val.map(cut_cat).astype('int')\n",
    "display(y_val_s.value_counts())\n",
    "roc_auc_score(y_val_s, val_probs, multi_class='ovo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметно, что значение целевой метрики на валидации выросло на 5 п.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим дообученную модель, чтобы ей векторизовать обучающую выборку для обучения логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./outputs were not used when initializing BertForTextRepresentation: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_ft = RepresentationModel(\n",
    "        model_type=\"bert\",\n",
    "        model_name=\"./outputs\",\n",
    "        use_cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем дообученным bert обучающую выборку и валидационную, выберем cls-эмбеддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.6 s, sys: 3.66 s, total: 1min 3s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_train = pd.DataFrame(torch.nn.functional.normalize(torch.tensor(model_ft.encode_sentences(upsed['text'], \n",
    "                                                                                  combine_strategy=0)))) # cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.47 s, sys: 284 ms, total: 4.75 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_val = pd.DataFrame(torch.nn.functional.normalize(torch.tensor(model_ft.encode_sentences(X_val['text'], \n",
    "                                                                                  combine_strategy=0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию на этих эмбеддингах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', max_iter=200, random_state=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(ft_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8142202096149465"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout = ft_val\n",
    "\n",
    "holdout_probs = pd.DataFrame(logit.predict_proba(holdout), columns=logit.classes_)\n",
    "h_i = holdout_probs.idxmax(axis=1)\n",
    "        \n",
    "for col in holdout_probs.columns:\n",
    "    holdout_probs[col].values[:] = 0\n",
    "            \n",
    "for row, idx in zip(holdout_probs.iterrows(), h_i):\n",
    "    row[1][idx] = 1\n",
    "    \n",
    "roc_auc_score(y_val, holdout_probs, multi_class='ovo', labels=logit.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество предсказаний на валидационной выборке также немного выше, чем у модели, использованной как классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Y60HHS5jKeN"
   },
   "source": [
    "## Предсказание теста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем дообученным rubert-tiny2 тестовую выборку (только столбец 'text')\n",
    "\n",
    "А также векторизуем тестовую выборке предобученным rubert-tiny2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 s, sys: 4.94 s, total: 48.9 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = pd.DataFrame(embed(test, test='test', cls=False))\n",
    "\n",
    "ft_test = pd.DataFrame(torch.nn.functional.normalize(torch.tensor(model_ft.encode_sentences(test['text'], \n",
    "                                                                                  combine_strategy=0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим предсказания для тестовой выборки дообученным bert-ом как классификатором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980343fec4a14d4d85bc7614bb4760cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b7449eaa994f07b04b968c329ea39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions, raw_outputs, _, __ = model_new.predict(list(test['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию на эмбеддингах дообученного bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_new = LogisticRegression(random_state=2, penalty='l2', C=0.9, class_weight='balanced', max_iter=200)\n",
    "logit_new.fit(ft_train, y_train)\n",
    "l_new_preds = pd.Series(logit_new.predict(ft_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы избежать переобучения, обучим k ближайших соседей и метод опороных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим k ближайших соседей на эмбеддингах предобученного bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', metric='cosine', n_neighbors=9,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9, weights='distance', metric='cosine', algorithm='brute', leaf_size=30)\n",
    "knn.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод опороных векторов на эмбеддингах предобученного bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(class_weight='balanced',\n",
       "                                                loss='hinge', random_state=42))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(loss='hinge', multi_class='ovr', class_weight='balanced',  random_state=42, intercept_scaling=1)\n",
    "\n",
    "clf = CalibratedClassifierCV(svm) \n",
    "clf.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее добавим предсказания этих моделей с небольшими весами в итоговое предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_bert_new_logit(b, k, s):\n",
    "    \n",
    "    # получим вероятности для классов дообученным bert-ом как классификатором\n",
    "    bert_soft_preds = softmax(raw_outputs, axis=1)\n",
    "    \n",
    "    # вероятности логистичекой регрессии на дообученных эмбеддингах\n",
    "    log_probs = logit_new.predict_proba(ft_test)\n",
    "    # вероятности ближайших соседей на предобученных эмбеддингах\n",
    "    knn_probs = knn.predict_proba(test_df)\n",
    "    # вероятности метода опорных векторов на предобученных эмбеддингах\n",
    "    svm_probs = clf.predict_proba(test_df)\n",
    "    \n",
    "    # смешиваем предсказания\n",
    "    blended = bert_soft_preds * b + log_probs * (1 - b - k - s) + knn_probs * k + svm_probs * s\n",
    "    blended = pd.DataFrame(blended, columns=logit_new.classes_)\n",
    "    \n",
    "    # отбираем категорию с большей вероятностью\n",
    "    blend = blended.idxmax(axis=1)\n",
    "    \n",
    "    # проставляем по словарю значения редких категорий (то, что мы сформировали в начале)\n",
    "    for idx in hand_cats.keys():\n",
    "        blend.iloc[idx] = hand_cats[idx]\n",
    "           \n",
    "    return blend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем веса для моделей:\n",
    "\n",
    "    0.25 - дообученный bert как классфикатор\n",
    "    0.05 - 9 ближайших соседей по косинусному расстоянию предобученных эмбеддингов\n",
    "    0.1 - метод опорных векторов на предобученных эмбеддингах\n",
    "    0.6 - логистическая регрессия на эмбеддингах дообученного bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_b_n = blend_bert_new_logit(0.25, 0.05, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('sample_solution.csv')\n",
    "ss['Категория'] = b_b_n\n",
    "from datetime import datetime\n",
    "nownow = datetime.now()\n",
    "filename = nownow.strftime(format='%d_%m_%y_%H_%M_%S')\n",
    "ss.to_csv(filename + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Курс_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
